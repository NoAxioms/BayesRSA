
6/11/2019
Testing gestures.py with gesture=None, ended with belief [0.0427, 0.5851, 0.3722]. It seems SVI will deviate from prior randomly if there is no reason to update it. Verified with 'useless observations.py'. How can we remedy this? Lowering learning rate helps a bit, but this seems pretty problematic. 
We could: ignore step if the gradient is too small, look for randomness in step direction and reset/ use a type of average. Run SVI twice, take average. Deal with this later
TODO TODAY:
	Heuristic decision maker
	Connect to baxter
	Stretch goals:
		Get lexicon to update during trial. Should exploit gesture.
		Filter out prepositions, verbs, etc.


~~~~~~~~TODO~~~~~~~~
~~Short Term:~~
Implement Fetch version:
	How to do intra-trial inference?
		For small data size, it may be worth it to maintain full trajectories in history - speech, gesture (uncompressed), desired item.
			Should a trajectory track the agent's belief in the desired object over time? This makes sense if the human can infer this belief and acts accordingly. However, our model assumes the human assumes the agent knows the lexicon; thus the human's estimation of the agent's belief will be incorrect. For now, assume the human treats the agent as having a uniform belief at all times.
	Add multi-word utterances (will probably need to use cost)
Compare to "Acquisition of Word-Object Associations from Human-Robot and Human-Human Dialogues"
Implement attribute_set model: maintain a list of words that are known to apply/not apply to each item, and a belief over the rest. 
	Should this be in the same file as the old version? 

~~Medium Term~~
Allow flexible vocabulary size. Transform datastructure when new words/objects are introduced.

~~Longer Term~~
Network with existing language/vision tools so that this acts as a complement.




Tricks to be used:
Online Updates: Use posterior as prior https://forum.pyro.ai/t/online-updates-of-guide/352


Thoughts:
An ideal system uses all the tricks.
We could blend together low, mid, and high sample complexity methods. At very low sample data, use direct histogram type methods (initialize s_0 as histogram). At mid, use this model. At high, use NN. The current rsa pyro method may take upwards of 7 seconds to converge, but scales well with data. Use existing networks when applicable for final version.
Should act based on most probable s_0 based on dirichlet concentration.

DO I want to add the option to restric tthe support of the word distributions? This could speed up learning with large item/word sets if used intelligently. Ignore for now.

Q: Does a dirichlet belief support the kind of inference we want? It would likely not if it treats all attributes independently.
	Testing face, moustache, glasses with moustache item never targeted. Did not make useful inference for moustache item. 
	Learning and using language via recursive pragmatic reasoning about other agents has probability of object given word, and maintains dirichlet prior over this. Starting with base listener feels weird, since we are the listener and we don't know jack.

We use pyro.set_rng(0) and do no other sampling (in att_set_test), yet the results are random?

6/7/2019:
Look up contextual deixis. We need to decide how to model gesture. In fetch, people seemed to point naively.
	We could look through fetch data and create model.
	google scholar queries (no relevant results in top 5):
		contextual deixis
		contextual deixis gesture
		rational gesture
		discriminative deictic gesture
		discriminative gesture generation
	Use Henny's gesture model?

6/8/2019 (6/7/2019)
Find out how to interface pyro, which requires python 3, with ros, which uses python 2.

6/9/2019
Eric says use tcp/websocket to interface python 2/3
Put intra-trial inference in main

6/10/2019
Should gesture and utterance be treated independently? For now.
Filter out structure words
Should we infer lexicon within a trial? If we allow abstract questions, ex. is this green, then kinda. Real question is, should we infer lexicon without strict supervision? If we plan to get proper supervision later, this may add unnecessary noise and waste time.
